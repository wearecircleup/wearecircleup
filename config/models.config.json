{
  "models": {
    "endpoint": "https://models.github.ai/inference/chat/completions",
    "primary": {
      "name": "gpt-4o",
      "maxTokens": 4096,
      "temperature": 0.7
    },
    "fallback": [
      {
        "name": "meta-llama/Llama-3.1-70B-Instruct",
        "maxTokens": 4096,
        "temperature": 0.7
      },
      {
        "name": "microsoft/Phi-3-medium-128k-instruct",
        "maxTokens": 2048,
        "temperature": 0.6
      }
    ],
    "retry": {
      "maxAttempts": 3,
      "backoffMs": 1000,
      "backoffMultiplier": 2
    }
  }
}
